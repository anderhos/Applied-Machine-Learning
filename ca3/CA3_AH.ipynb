{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepocessing data\n",
    "# Source lecture DAT200. File: rawDataInspection_01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CA3-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values!\n"
     ]
    }
   ],
   "source": [
    "# Search for missing values\n",
    "missing = np.asarray(df.isnull().sum())\n",
    "if missing.any():\n",
    "    print(\"Dataset has missing values\")\n",
    "else:\n",
    "    print('No missing values!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11',\n",
      "       'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21',\n",
      "       'f22', 'f23', 'f24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# features index\n",
    "c_first = 1\n",
    "c_last = 25    # not included\n",
    "# Assign features to X matrix and corresponding labels to vector y\n",
    "X, y = df.iloc[:, c_first:c_last].values, df.iloc[:, 25]\n",
    "print(f\"Selected features:\", df.iloc[:, c_first:c_last].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the unique class labels\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "seed = 1\n",
    "test_size = 0.3\n",
    "\n",
    "# Splitting data with default parameters\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "# Standardizing our data to make algorithms behave better\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot decision regions. Works only when two features are selected\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # Source Python for Machine Learning ch05\n",
    "    # setup marker generator and colormap\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx2.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot examples by class\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=colors[idx],\n",
    "                    marker=markers[idx], label=cl,\n",
    "                    edgecolor='black')\n",
    "    # highlight test examples\n",
    "    if test_idx:\n",
    "        # plot all examples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0], X_test[:, 1],\n",
    "                    c='', edgecolor='black', alpha=1.0,\n",
    "                    linewidth=1, marker='o',\n",
    "                    s=100, label='test set')\n",
    "    plt.xlabel('First feature [standardized]')\n",
    "    plt.ylabel('Second feature [standardized]')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined(X_train, X_test, y_train, y_test):\n",
    "    # Stacking the data before plotting\n",
    "    X_combined = X_train + X_test\n",
    "    y_combined = y_train + y_test\n",
    "    return X_combined, y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_test_size(classifier, X, y, test_size_list, seed, feature_extraction=None, n_components=None):\n",
    "    # Accuracy for different test_train_splits\n",
    "    for size in test_size_list:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size, stratify=y,\n",
    "                                                            random_state=seed)\n",
    "        X_train_std = sc.fit_transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "        if feature_extraction == PCA:\n",
    "            # Dimensionality reduction through PCA\n",
    "            pca = PCA(n_components=n_components, random_state=1)\n",
    "            X_train_pca = pca.fit_transform(X_train_std, y_train)\n",
    "            X_test_pca = pca.transform(X_test_std)\n",
    "            classifier.fit(X_train_pca, y_train)\n",
    "            y_pred = classifier.predict(X_test_pca)\n",
    "            print(f'Misclassified examples PCA: {(y_test != y_pred).sum()}')\n",
    "            print('Accuracy PCA: {:.3}'.format(classifier.score(X_test_pca, y_test)))\n",
    "            print(f'Test size: {size}')\n",
    "        elif feature_extraction == LDA:\n",
    "            lda = LDA(n_components=n_components)\n",
    "            X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "            X_test_lda = lda.transform(X_test_std)\n",
    "            classifier.fit(X_train_lda, y_train)\n",
    "            print('Accuracy LDA: {:.3}'.format(classifier.score(X_test_lda, y_test)))\n",
    "            print(f'Test size: {size}')\n",
    "                \n",
    "        else:\n",
    "            classifier.fit(X_train_std, y_train)\n",
    "            y_pred = classifier.predict(X_test_std)\n",
    "            print(f'Misclassified examples: {(y_test != y_pred).sum()}')\n",
    "            print('Training Accuracy: {:.3}'.format(classifier.score(X_train_std, y_train)))\n",
    "            print('Accuracy: {:.3}'.format(classifier.score(X_test_std, y_test)))\n",
    "            print(f'Test size: {size}')\n",
    "    # Note: After function call test size is the last index of test_size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cumulative sum of explained variances\n",
    "def plot_var_exp(n_components):\n",
    "    pca = PCA(n_components=n_components, random_state=1)\n",
    "    pca.fit_transform(X_train_std)\n",
    "    pca.fit(X_test_std)\n",
    "    var_exp = pca.explained_variance_ratio_\n",
    "    cum_var_exp = np.cumsum(var_exp)\n",
    "    plt.bar(range(1, n_components + 1), var_exp, alpha=0.5, align='center',\n",
    "            label='Individual explained variances')\n",
    "    plt.step(range(1, n_components + 1), cum_var_exp, where='mid',\n",
    "             label='Cumulative explained variances')\n",
    "    plt.xlabel('Explained variance ratio')\n",
    "    plt.ylabel('Principal component index')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C:  0.1\n",
      "Max acurracy score: 0.488\n",
      "Test size:  0.3\n"
     ]
    }
   ],
   "source": [
    "# Fit decision tree classifier and calculate accuracy for different train_test_splits\n",
    "C_list = [100, 10, 1, 0.1, 0.01]\n",
    "max_score = 0\n",
    "for C in C_list:\n",
    "    lr_temp = LogisticRegression(penalty='l1', C=C, solver='liblinear', random_state=seed)\n",
    "    lr_temp.fit(X_train_std, y_train)\n",
    "    score = lr_temp.score(X_test_std, y_test)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        C_best = C\n",
    "\n",
    "print(\"Best C: \", C_best)\n",
    "print(\"Max acurracy score: {:.3}\".format(max_score))\n",
    "print(\"Test size: \", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Decision tree and calculate accuracy for different train_test_splits\n",
    "test_size_list = [0.6, 0.3, 0.1, 0.05, 0.01]\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified examples: 2250\n",
      "Training Accuracy: 0.459\n",
      "Accuracy: 0.472\n",
      "Test size: 0.6\n",
      "Misclassified examples: 1120\n",
      "Training Accuracy: 0.483\n",
      "Accuracy: 0.475\n",
      "Test size: 0.3\n",
      "Misclassified examples: 351\n",
      "Training Accuracy: 0.476\n",
      "Accuracy: 0.506\n",
      "Test size: 0.1\n",
      "Misclassified examples: 170\n",
      "Training Accuracy: 0.477\n",
      "Accuracy: 0.522\n",
      "Test size: 0.05\n",
      "Misclassified examples: 41\n",
      "Training Accuracy: 0.479\n",
      "Accuracy: 0.431\n",
      "Test size: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Fit Decision tree and calculate accuracy for different train_test_splits\n",
    "test_size_list = [0.6, 0.3, 0.1, 0.05, 0.01]\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', max_depth=3, min_weight_fraction_leaf=0.2, \n",
    "                                    random_state=seed)\n",
    "fit_test_size(tree_model, X, y, test_size_list, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LDA: 0.501\n",
      "Test size: 0.3\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "tree_model.fit(X_train_lda, y_train)\n",
    "print('Accuracy LDA: {:.3}'.format(tree_model.score(X_test_lda, y_test)))\n",
    "print(f'Test size: {test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LDA: 0.494\n",
      "Test size: 0.6\n",
      "Accuracy LDA: 0.501\n",
      "Test size: 0.3\n",
      "Accuracy LDA: 0.506\n",
      "Test size: 0.1\n",
      "Accuracy LDA: 0.528\n",
      "Test size: 0.05\n",
      "Accuracy LDA: 0.514\n",
      "Test size: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy with feature extraction\n",
    "fit_test_size(tree_model, X, y, test_size_list, seed, feature_extraction=LDA, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified examples PCA: 2543\n",
      "Accuracy PCA: 0.404\n",
      "Test size: 0.6\n",
      "Misclassified examples PCA: 1248\n",
      "Accuracy PCA: 0.415\n",
      "Test size: 0.3\n",
      "Misclassified examples PCA: 412\n",
      "Accuracy PCA: 0.421\n",
      "Test size: 0.1\n",
      "Misclassified examples PCA: 211\n",
      "Accuracy PCA: 0.407\n",
      "Test size: 0.05\n",
      "Misclassified examples PCA: 44\n",
      "Accuracy PCA: 0.389\n",
      "Test size: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy with feature extraction\n",
    "fit_test_size(tree_model, X, y, test_size_list, seed, feature_extraction=PCA, n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking into the data\n",
    "\n",
    "comment: Might skip this in final version\n",
    "\n",
    "* Search for correlations\n",
    "* Look for outliers\n",
    "* Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.iloc[:, 1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.202026</td>\n",
       "      <td>0.804586</td>\n",
       "      <td>0.401941</td>\n",
       "      <td>156.874930</td>\n",
       "      <td>166.643360</td>\n",
       "      <td>196.047271</td>\n",
       "      <td>168.302195</td>\n",
       "      <td>238.272512</td>\n",
       "      <td>230.066717</td>\n",
       "      <td>219.825159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398284</td>\n",
       "      <td>530.048818</td>\n",
       "      <td>0.224254</td>\n",
       "      <td>297.630979</td>\n",
       "      <td>0.221186</td>\n",
       "      <td>0.331006</td>\n",
       "      <td>0.030905</td>\n",
       "      <td>5.881964</td>\n",
       "      <td>4.886747</td>\n",
       "      <td>2.899268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493933</td>\n",
       "      <td>0.396547</td>\n",
       "      <td>0.490325</td>\n",
       "      <td>80.914806</td>\n",
       "      <td>74.588417</td>\n",
       "      <td>107.521931</td>\n",
       "      <td>77.616408</td>\n",
       "      <td>207.299347</td>\n",
       "      <td>207.017288</td>\n",
       "      <td>198.373088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707898</td>\n",
       "      <td>1927.718921</td>\n",
       "      <td>0.417120</td>\n",
       "      <td>699.293958</td>\n",
       "      <td>0.376378</td>\n",
       "      <td>0.451033</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>1.536845</td>\n",
       "      <td>2.878474</td>\n",
       "      <td>1.860700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.325500</td>\n",
       "      <td>-1.206000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>111.037400</td>\n",
       "      <td>105.016925</td>\n",
       "      <td>88.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.124575</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>173.704850</td>\n",
       "      <td>167.636150</td>\n",
       "      <td>150.273100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>289.366625</td>\n",
       "      <td>281.537275</td>\n",
       "      <td>284.385325</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>223.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1036.000000</td>\n",
       "      <td>1036.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>977.000000</td>\n",
       "      <td>1924.134700</td>\n",
       "      <td>1924.134700</td>\n",
       "      <td>1070.361600</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35448.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11140.000000</td>\n",
       "      <td>4.491700</td>\n",
       "      <td>4.491700</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f1           f2           f3           f4           f5  \\\n",
       "count  7108.000000  7108.000000  7108.000000  7108.000000  7108.000000   \n",
       "mean      1.202026     0.804586     0.401941   156.874930   166.643360   \n",
       "std       0.493933     0.396547     0.490325    80.914806    74.588417   \n",
       "min       1.000000     0.000000     0.000000     0.000000    20.000000   \n",
       "25%       1.000000     1.000000     0.000000    99.000000   119.000000   \n",
       "50%       1.000000     1.000000     0.000000   139.000000   159.000000   \n",
       "75%       1.000000     1.000000     1.000000   199.000000   199.000000   \n",
       "max       8.000000     1.000000     1.000000  1036.000000  1036.000000   \n",
       "\n",
       "                f6           f7           f8           f9          f10  ...  \\\n",
       "count  7108.000000  7108.000000  7108.000000  7108.000000  7108.000000  ...   \n",
       "mean    196.047271   168.302195   238.272512   230.066717   219.825159  ...   \n",
       "std     107.521931    77.616408   207.299347   207.017288   198.373088  ...   \n",
       "min      20.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%     119.000000   119.000000   111.037400   105.016925    88.459000  ...   \n",
       "50%     179.000000   159.000000   173.704850   167.636150   150.273100  ...   \n",
       "75%     239.000000   199.000000   289.366625   281.537275   284.385325  ...   \n",
       "max    1628.000000   977.000000  1924.134700  1924.134700  1070.361600  ...   \n",
       "\n",
       "               f15           f16          f17           f18          f19  \\\n",
       "count  7108.000000   7108.000000  7108.000000   7108.000000  7108.000000   \n",
       "mean      0.398284    530.048818     0.224254    297.630979     0.221186   \n",
       "std       0.707898   1927.718921     0.417120    699.293958     0.376378   \n",
       "min       0.000000      0.000000     0.000000      0.000000    -4.325500   \n",
       "25%       0.000000      0.000000     0.000000      0.000000     0.073800   \n",
       "50%       0.000000      0.000000     0.000000      0.000000     0.147800   \n",
       "75%       1.000000    223.750000     0.000000    298.000000     0.259100   \n",
       "max       5.000000  35448.000000     1.000000  11140.000000     4.491700   \n",
       "\n",
       "               f20          f21          f22          f23          f24  \n",
       "count  7108.000000  7108.000000  7108.000000  7108.000000  7108.000000  \n",
       "mean      0.331006     0.030905     5.881964     4.886747     2.899268  \n",
       "std       0.451033     0.027579     1.536845     2.878474     1.860700  \n",
       "min      -1.206000     0.000500     2.000000     1.000000     1.000000  \n",
       "25%       0.124575     0.015300     5.000000     2.000000     1.000000  \n",
       "50%       0.220600     0.023400     6.000000     4.000000     2.000000  \n",
       "75%       0.354800     0.036900     7.000000     7.000000     4.000000  \n",
       "max       4.491700     0.362300    10.000000    10.000000    10.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Descriptive statistics\n",
    "# =============================================================================\n",
    "df_X.describe()\n",
    "#df.iloc[:, 16].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for positive values f16\n",
    "\n",
    "positive_f16 = np.where(df['f16']>0, True, False)\n",
    "# count True\n",
    "positive_f16.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        5290.0\n",
       "3         397.0\n",
       "6        2248.0\n",
       "11        358.0\n",
       "12       2306.0\n",
       "         ...   \n",
       "7083     1569.0\n",
       "7089      596.0\n",
       "7090    10556.0\n",
       "7099      517.0\n",
       "7102      477.0\n",
       "Name: f16, Length: 2145, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with zero values\n",
    "\n",
    "extract_positive_f16 = df[df['f16']>0]['f16']\n",
    "extract_positive_f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x190e9fc9e80>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram positive f16\n",
    "extract_positive_f16.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2145.000000\n",
       "mean      1756.450816\n",
       "std       3187.966249\n",
       "min         20.000000\n",
       "25%        318.000000\n",
       "50%        676.000000\n",
       "75%       1670.000000\n",
       "max      35448.000000\n",
       "Name: f16, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics for posive f16\n",
    "\n",
    "extract_positive_f16.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Histograms\n",
    "# =============================================================================\n",
    "\n",
    "df.iloc[:, 16].hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes AH: Possible outliers f16, very high max relative to the rest.\n",
    "Also a lot of zero values more than two-thirds. Consider dropping the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Density plots\n",
    "# =============================================================================\n",
    "\n",
    "df['f16'].plot(kind='density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4366    35448.0\n",
       "6861    35448.0\n",
       "3295    30016.0\n",
       "5336    30016.0\n",
       "3089    30016.0\n",
       "3764    30016.0\n",
       "1108    24987.0\n",
       "4808    22514.0\n",
       "1539    22218.0\n",
       "2019    22218.0\n",
       "3997    22218.0\n",
       "2481    22218.0\n",
       "2160    17872.0\n",
       "4439    17872.0\n",
       "4162    17872.0\n",
       "1876    17019.0\n",
       "2058    17019.0\n",
       "6419    15604.0\n",
       "6589    15604.0\n",
       "332     15604.0\n",
       "2150    15319.0\n",
       "3985    15319.0\n",
       "2888    15319.0\n",
       "1597    15319.0\n",
       "6767    15319.0\n",
       "4959    15319.0\n",
       "1870    14971.0\n",
       "2067    14824.0\n",
       "4923    14824.0\n",
       "6088    14824.0\n",
       "62      14824.0\n",
       "4543    14146.0\n",
       "2246    14146.0\n",
       "6681    14146.0\n",
       "343     14146.0\n",
       "1084    14146.0\n",
       "5137    14146.0\n",
       "929     14047.0\n",
       "3443    12433.0\n",
       "680     12433.0\n",
       "4793    12433.0\n",
       "4609    12432.0\n",
       "5079    12432.0\n",
       "5633    12364.0\n",
       "4887    12364.0\n",
       "4460    12185.0\n",
       "1720    11988.0\n",
       "1699    11988.0\n",
       "1639    11655.0\n",
       "66      11655.0\n",
       "Name: f16, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort values for f16 in descending order\n",
    "\n",
    "df['f16'].sort_values(ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['f16'], ascending=False)[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Skip the six first datapoints from the sorting above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Plot correlation matrix\n",
    "# =============================================================================\n",
    "\n",
    "# plot correlation matrix for the first four features\n",
    "df_sub = df.iloc[:, 21:25]\n",
    "correlations = df_sub.corr()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0, 5, 1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(list(df_sub.columns))\n",
    "ax.set_yticklabels(list(df_sub.columns))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_f15f16 = df.iloc[:, [15, 16]].corr()\n",
    "corr_f15f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations all f16\n",
    "corr_all = df_X.corr()\n",
    "corr_all.iloc[:, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_X_std = sc.fit_transform(df_X)\n",
    "df_X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_X_std[14], df_X_std[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
