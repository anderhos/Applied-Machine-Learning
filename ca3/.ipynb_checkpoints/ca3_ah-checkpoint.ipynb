{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepocessing data\n",
    "# Source lecture DAT200. File: rawDataInspection_01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CA3-train.csv')\n",
    "df_test = pd.read_csv('CA3-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values!\n"
     ]
    }
   ],
   "source": [
    "# Search for missing values\n",
    "missing = np.asarray(df_test.isnull().sum())\n",
    "if missing.any():\n",
    "    print(\"Dataset has missing values\")\n",
    "else:\n",
    "    print('No missing values!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11',\n",
      "       'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21',\n",
      "       'f22', 'f23', 'f24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# features index\n",
    "c_first = 1\n",
    "c_last = 25    # not included\n",
    "# Assign features to X matrix. Assign to X_train and y_train\n",
    "X_train, y_train = df.iloc[:, c_first:c_last].values, df.iloc[:, 25]\n",
    "print(f\"Selected features:\", df.iloc[:, c_first:c_last].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X_test\n",
    "X_test = df_test.iloc[:, c_first:c_last].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "seed = 1\n",
    "\n",
    "# Standardizing our data to make algorithms behave better\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Random forest and calculate accuracy for different train_test_splits\n",
    "forest = RandomForestClassifier(n_estimators = 100, criterion='gini', max_depth=25, n_jobs = -1, random_state=seed)\n",
    "forest.fit(X_train_std, y_train)\n",
    "y_pred = forest.predict(X_test_std)    # predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 : 1271\n",
      "Share of total: 0.332\n",
      "Class 1 : 1702\n",
      "Share of total: 0.445\n",
      "Class 2 : 855\n",
      "Share of total: 0.223\n"
     ]
    }
   ],
   "source": [
    "# Count each predicted class label\n",
    "c = Counter(y_pred)\n",
    "for i in range(3):\n",
    "    print(\"Class\", i, \":\", c[i])\n",
    "    print(\"Share of total: {:.3}\".format(c[i]/sum(c.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy without feature extraction\n",
    "fit_test_size(forest, X, y, test_size_list, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy with feature extraction\n",
    "fit_test_size(forest, X, y, test_size_list, seed, feature_extraction=LDA, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy with feature extraction\n",
    "fit_test_size(forest, X, y, test_size_list, seed, feature_extraction=PCA, n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking into the data\n",
    "\n",
    "comment: Might skip this in final version\n",
    "\n",
    "* Search for correlations\n",
    "* Look for outliers\n",
    "* Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.iloc[:, 1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Descriptive statistics\n",
    "# =============================================================================\n",
    "df_X.describe()\n",
    "#df.iloc[:, 16].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for positive values f16\n",
    "\n",
    "positive_f16 = np.where(df['f16']>0, True, False)\n",
    "# count True\n",
    "positive_f16.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with zero values\n",
    "\n",
    "extract_positive_f16 = df[df['f16']>0]['f16']\n",
    "extract_positive_f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram positive f16\n",
    "extract_positive_f16.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for posive f16\n",
    "\n",
    "extract_positive_f16.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Histograms\n",
    "# =============================================================================\n",
    "\n",
    "df.iloc[:, 16].hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes AH: Possible outliers f16, very high max relative to the rest.\n",
    "Also a lot of zero values more than two-thirds. Consider dropping the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Density plots\n",
    "# =============================================================================\n",
    "\n",
    "df['f16'].plot(kind='density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values for f16 in descending order\n",
    "\n",
    "df['f16'].sort_values(ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['f16'], ascending=False)[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Skip the six first datapoints from the sorting above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Plot correlation matrix\n",
    "# =============================================================================\n",
    "\n",
    "# plot correlation matrix for the first four features\n",
    "df_sub = df.iloc[:, 21:25]\n",
    "correlations = df_sub.corr()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0, 5, 1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(list(df_sub.columns))\n",
    "ax.set_yticklabels(list(df_sub.columns))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_f15f16 = df.iloc[:, [15, 16]].corr()\n",
    "corr_f15f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations all f16\n",
    "corr_all = df_X.corr()\n",
    "corr_all.iloc[:, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_X_std = sc.fit_transform(df_X)\n",
    "df_X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_X_std[14], df_X_std[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
